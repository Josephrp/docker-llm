# ==============================================================================
# BASE

ARG FROM_TAG

FROM nvcr.io/nvidia/pytorch:${FROM_TAG} as base

ENV DEBIAN_FRONTEND=noninteractive

# APT Update
RUN apt-get update

# CUDA v11
# Because of https://github.com/vllm-project/vllm/issues/1369
RUN apt-get install -y cuda-toolkit-11.7

# Pip
RUN curl -s https://bootstrap.pypa.io/get-pip.py -o get-pip.py && \
  python get-pip.py --force-reinstall && \
  rm get-pip.py

# PyTorch
RUN pip install --upgrade torch

# ==============================================================================
# SERVER

FROM base as server

EXPOSE 8000

ARG HF_TOKEN
ARG MODEL

ENV HF_TOKEN=$HF_TOKEN
ENV HOST=0.0.0.0
ENV MODEL=$MODEL
ENV PORT=8000
# https://huggingface.co/docs/transformers/installation
ENV TENSOR_PARALLEL_SIZE=1

WORKDIR /workspace

RUN pip install \
  huggingface_hub \
  xformers \
  vllm

RUN python -c "import huggingface_hub; huggingface_hub.login(token='${HF_TOKEN}', add_to_git_credential=False)"
RUN python -c "import huggingface_hub; huggingface_hub.hf_hub_download(repo_id='${MODEL}', filename='config.json', cache_dir='./models')"

COPY ./entrypoint.sh /workspace/entrypoint.sh

ENTRYPOINT [ "/workspace/entrypoint.sh" ]
